"""
Simple AI Processor - Production-Grade Architecture

PRINCIPLE: ONE AI CALL ‚Üí EXTRACT ALL ‚Üí VALIDATE ‚Üí TEMPLATE

NO HALLUCINATION - AI –Ω–µ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç —Å–≤–æ–±–æ–¥–Ω–æ!
"""
import json
import logging
from typing import Dict, Any, Optional, Tuple
import openai

from .schemas import EXTRACTION_SCHEMA, EXTRACTION_PROMPT
from .templates import TEMPLATES, format_template
from .rules import BusinessRules
from .pricing import PricingCalculator
from .context import DialogueContextManager
from .function_handlers import (
    execute_function,
    handle_create_bitrix_deal,
    handle_create_bitrix_deal_legal
)
from .config import DEFAULT_MODEL
from .micro_prompts import build_micro_prompt

import sys
sys.path.insert(0, '/home/ludskoe/kwork/pepsiai/se_base')
from chats_log import api as chats_log

logger = logging.getLogger(__name__)


class SimpleAIProcessor:
    """
    –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π AI –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
    
    –ê–ª–≥–æ—Ä–∏—Ç–º:
    1. ONE AI CALL: –∏–∑–≤–ª–µ—á—å –í–°–ï –¥–∞–Ω–Ω—ã–µ (structured output)
    2. BUSINESS RULES: –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å customer_type, –¥–µ–π—Å—Ç–≤–∏—è (NO AI!)
    3. TEMPLATE: –≤—ã–±—Ä–∞—Ç—å –∏ –∑–∞–ø–æ–ª–Ω–∏—Ç—å —à–∞–±–ª–æ–Ω (NO AI!)
    4. DONE: –≤–µ—Ä–Ω—É—Ç—å –æ—Ç–≤–µ—Ç
    
    –†–µ–∑—É–ª—å—Ç–∞—Ç: NO HALLUCINATION, FAST, CHEAP
    """
    
    def __init__(self):
        logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è SimpleAIProcessor")
        
        self.pricing_calculator = PricingCalculator()
        self.context_manager = DialogueContextManager()
        self.business_rules = BusinessRules()
        
        self._init_openai_client()
        
        # State
        self._last_extracted_data = {}
        self._last_customer_type = 'unknown'
    
    def _init_openai_client(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI"""
        import config
        try:
            api_key = config.Production.OPENAI_API_KEY
            base_url = config.Production.OPENAI_BASE_URL
            
            self.openai_client = openai.OpenAI(api_key=api_key, base_url=base_url)
            
            # Test connection
            test_response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": "test"}],
                max_tokens=5,
                timeout=10
            )
            
            logger.info("‚úÖ OpenAI client initialized")
            self.use_openai = True
            
        except Exception as e:
            logger.error(f"‚ùå OpenAI initialization failed: {e}")
            self.openai_client = None
            self.use_openai = False
    
    def process(
        self, 
        message: str, 
        chat_id: str = None,
        ad_data: dict = None,
        avito_message_model = None,
        return_metadata: bool = False
    ) -> Any:
        """
        –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è
        
        Args:
            message: –¢–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
            chat_id: ID —á–∞—Ç–∞
            ad_data: –î–∞–Ω–Ω—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è
            avito_message_model: –ú–æ–¥–µ–ª—å –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è (optional)
            return_metadata: –í–µ—Ä–Ω—É—Ç—å metadata
        
        Returns:
            str: –û—Ç–≤–µ—Ç –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞
            –∏–ª–∏ (str, dict): (–æ—Ç–≤–µ—Ç, metadata) –µ—Å–ª–∏ return_metadata=True
        """
        import time
        start_time = time.time()
        
        logger.info(f"Processing: '{message[:50]}...'")
        
        try:
            # Add to context
            if chat_id:
                self.context_manager.add_message(chat_id, message, is_user=True)
            
            # 1. EXTRACT ALL DATA (ONE AI CALL)
            extracted = self._extract_all_data(message, chat_id)
            self._last_extracted_data = extracted
            
            logger.info(f"üìä Extracted: intent={extracted['intent']}, "
                       f"city={extracted.get('city')}, "
                       f"people={extracted.get('people')}, "
                       f"keywords={extracted.get('keywords', [])}")
            
            # 2. BUSINESS RULES (NO AI!)
            response, metadata = self._apply_business_logic(message, extracted, chat_id, ad_data)
            
            # 3. LOG TO chats_log (–¥–ª—è KPI Dashboard)
            response_time_ms = int((time.time() - start_time) * 1000)
            self._log_interaction(
                chat_id=chat_id,
                message=message,
                response=response,
                metadata=metadata,
                extracted=extracted,
                response_time_ms=response_time_ms,
                avito_message_model=avito_message_model
            )
            
            # Add to context
            if chat_id:
                self.context_manager.add_message(chat_id, response, is_user=False)
            
            if return_metadata:
                return response, metadata
            
            return response
            
        except Exception as e:
            logger.error(f"‚ùå Error in process(): {e}")
            import traceback
            logger.error(traceback.format_exc())
            
            # üö® –ê–õ–ï–†–¢ –ê–î–ú–ò–ù–ê–ú –ø—Ä–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π –æ—à–∏–±–∫–µ
            try:
                import bot
                error_msg = (
                    f"üö® CRITICAL: SimpleAIProcessor.process() failed\n\n"
                    f"Chat: {chat_id}\n"
                    f"Message: {message[:100]}\n"
                    f"Error: {str(e)[:200]}\n\n"
                    f"Trace: {traceback.format_exc()[:400]}"
                )
                bot.send_message(error_msg)
                logger.info("‚úÖ Critical error alert sent")
            except Exception as alert_err:
                logger.error(f"Failed to send alert: {alert_err}")
            
            # Fallback –æ—Ç–≤–µ—Ç
            fallback = format_template('error_fallback')
            
            # –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É
            if avito_message_model:
                try:
                    self._log_interaction(
                        message=message,
                        response=fallback,
                        chat_id=chat_id,
                        extracted={'intent': 'error', 'city': '', 'people': 0, 'hours': 0, 'phone': ''},
                        metadata={'action': 'error_fallback', 'error': str(e)[:200]},
                        response_time_ms=0,
                        avito_message_model=avito_message_model
                    )
                except Exception as log_err:
                    logger.error(f"Failed to log error: {log_err}")
            
            if return_metadata:
                return fallback, {'error': str(e), 'action': 'error_fallback'}
            return fallback
    
    def _extract_all_data(self, message: str, chat_id: str = None) -> Dict[str, Any]:
        """
        –û–î–ò–ù AI CALL –∏–∑–≤–ª–µ–∫–∞–µ—Ç –í–°–ï –¥–∞–Ω–Ω—ã–µ
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Structured Output (JSON mode) - NO HALLUCINATION!
        """
        if not self.use_openai:
            logger.warning("OpenAI not available, using fallback")
            return self._fallback_extraction(message)
        
        try:
            context_messages = []
            if chat_id:
                try:
                    history = chats_log.get_chat_history(chat_id, limit=5)
                    context_messages = history[-5:] if history else []
                    logger.debug(f"–ó–∞–≥—Ä—É–∂–µ–Ω–∞ –∏—Å—Ç–æ—Ä–∏—è –∏–∑ –ë–î: {len(context_messages)} —Å–æ–æ–±—â–µ–Ω–∏–π")
                except Exception as history_err:
                    logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏ –∏–∑ –ë–î: {history_err}")
                    history = self.context_manager.get_openai_messages(chat_id, limit=3)
                    context_messages = history[-3:] if history else []
            
            messages = context_messages + [
                {"role": "system", "content": EXTRACTION_PROMPT},
                {"role": "user", "content": message}
            ]
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                response_format={
                    "type": "json_schema",
                    "json_schema": {
                        "name": "data_extraction",
                        "strict": True,
                        "schema": EXTRACTION_SCHEMA
                    }
                },
                temperature=0,
                max_tokens=500
            )
            
            extracted = json.loads(response.choices[0].message.content)
            logger.info(f"ai extracted data: {extracted}")
            
            if chat_id and hasattr(self, '_last_extracted_data'):
                previous = self._last_extracted_data
                if not extracted.get('city') and previous.get('city'):
                    extracted['city'] = previous['city']
                if not extracted.get('people') and previous.get('people'):
                    extracted['people'] = previous['people']
                if not extracted.get('hours') and previous.get('hours'):
                    extracted['hours'] = previous['hours']
                if not extracted.get('phone') and previous.get('phone'):
                    extracted['phone'] = previous['phone']
                
                logger.info(f"üìã Merged with previous: city={extracted['city']}, people={extracted['people']}, hours={extracted['hours']}")
            
            return extracted
            
        except Exception as e:
            logger.error(f"‚ùå Extraction failed: {e}")
            return self._fallback_extraction(message)
    
    def _fallback_extraction(self, message: str) -> Dict[str, Any]:
        """Fallback –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –±–µ–∑ AI (–ø—Ä–æ—Å—Ç—ã–µ regex)"""
        import re
        
        extracted = {
            "intent": "ask_price",
            "city": "",
            "people": 0,
            "hours": 0,
            "phone": "",
            "keywords": [],
            "work_description": "",
            "has_special_items": False,
            "single_item_weight": 0,
            "floor": 0,
            "has_elevator": False,
            "urgency": "unknown",
            "is_forbidden_service": False,
            "confidence": 0.5
        }
        
        # Extract phone
        phone_match = re.search(r'(?:\+7|8|7)?[\s\-]?\(?(\d{3})\)?[\s\-]?(\d{3})[\s\-]?(\d{2})[\s\-]?(\d{2})', message)
        if phone_match:
            extracted['phone'] = ''.join(phone_match.groups())
            extracted['intent'] = 'provide_phone'
        
        # Extract people
        people_match = re.search(r'(\d+)\s*(?:–≥—Ä—É–∑—á–∏–∫|—á–µ–ª–æ–≤–µ–∫|–≥—Ä—É–∑|—Ä–µ–±—è—Ç)', message.lower())
        if people_match:
            extracted['people'] = int(people_match.group(1))
        
        # Extract hours
        hours_match = re.search(r'(\d+)\s*(?:—á–∞—Å|—á\b)', message.lower())
        if hours_match:
            extracted['hours'] = int(hours_match.group(1))
        
        # Extract city (simple patterns)
        for city in ['–º–æ—Å–∫–≤', '–ø–µ—Ç–µ—Ä–±—É—Ä–≥', '–∫–∞–∑–∞–Ω', '–µ–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥', '–Ω–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫', '—Å–∞–º–∞—Ä', '–∫—Ä–∞—Å–Ω–æ–¥–∞—Ä', '—Ä–æ—Å—Ç–æ–≤']:
            if city in message.lower():
                if city == '–º–æ—Å–∫–≤':
                    extracted['city'] = '–ú–æ—Å–∫–≤–∞'
                elif city == '–ø–µ—Ç–µ—Ä–±—É—Ä–≥':
                    extracted['city'] = '–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥'
                elif city == '–∫–∞–∑–∞–Ω':
                    extracted['city'] = '–ö–∞–∑–∞–Ω—å'
                break
        
        # Extract keywords
        for keyword in ['–æ—Ñ–∏—Å', '—Å—á–µ—Ç', '–¥–æ–≥–æ–≤–æ—Ä', '—é—Ä–ª–∏—Ü', '–∫–æ–º–ø–∞–Ω–∏', '–∫–≤–∞—Ä—Ç–∏—Ä', '–ø–µ—Ä–µ–µ–∑–¥', '—Ç–∞–∫–µ–ª–∞–∂', '—Å–µ–π—Ñ', '–ø–∏–∞–Ω–∏–Ω–æ']:
            if keyword in message.lower():
                extracted['keywords'].append(keyword)
        
        return extracted
    
    def _count_repeated_actions(self, chat_id: str) -> Dict[str, int]:
        """
        –ü–æ–¥—Å—á–∏—Ç–∞—Ç—å —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –∫–∞–∂–¥–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ –ø–æ–≤—Ç–æ—Ä—è–ª–æ—Å—å –ø–æ–¥—Ä—è–¥
        
        Returns:
            {"action_name": count, ...}
        """
        if not chat_id:
            return {}
        
        history = self.context_manager.get_context(chat_id, limit=10)
        action_counts = {}
        last_action = None
        consecutive_count = 0
        
        for msg in reversed(history):
            if msg.get('is_user'):
                continue
            
            # –ü–æ–ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å action –∏–∑ metadata (–µ—Å–ª–∏ —Å–æ—Ö—Ä–∞–Ω—è–ª—Å—è)
            # –ò–ª–∏ –∏–∑ —à–∞–±–ª–æ–Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è
            msg_text = msg.get('message', '')
            
            # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –æ–ø—Ä–µ–¥–µ–ª—è–µ–º action –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º
            current_action = None
            if '–ü–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç–µ' in msg_text or '—É—Ç–æ—á–Ω–∏—Ç' in msg_text.lower():
                current_action = 'clarify'
            elif '—Ç–µ–ª–µ—Ñ–æ–Ω' in msg_text.lower() and '–æ—Å—Ç–∞–≤—å—Ç–µ' in msg_text.lower():
                current_action = 'ask_phone'
            elif '–≥–æ—Ä–æ–¥' in msg_text.lower():
                current_action = 'ask_city'
            elif '–°–∫–æ–ª—å–∫–æ' in msg_text:
                current_action = 'ask_details'
            
            if current_action:
                if current_action == last_action:
                    consecutive_count += 1
                else:
                    if last_action:
                        action_counts[last_action] = consecutive_count
                    last_action = current_action
                    consecutive_count = 1
        
        if last_action:
            action_counts[last_action] = consecutive_count
        
        return action_counts
    
    def _analyze_context_with_ai(self, extracted: Dict, chat_id: str = None) -> Dict[str, Any]:
        """
        AI-–∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–∏–∞–ª–æ–≥–∞ –¥–ª—è —É–º–Ω–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è:
        - –¢–∏–ø –∫–ª–∏–µ–Ω—Ç–∞ (—É—á–∏—Ç—ã–≤–∞—è –≤–µ—Å—å –∫–æ–Ω—Ç–µ–∫—Å—Ç, –Ω–µ —Ç–æ–ª—å–∫–æ keywords)
        - –°–ª–µ–¥—É—é—â–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ (–µ—Å–ª–∏ –∑–∞—Å—Ç—Ä—è–ª–∏)
        - –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ —Å–¥–µ–ª–∫–µ
        """
        if not self.use_openai or not chat_id:
            return {
                'customer_type': 'unknown',
                'customer_confidence': 0.5,
                'next_action': 'ask_details',
                'reasoning': 'AI unavailable',
                'ready_for_deal': False
            }
        
        try:
            history = self.context_manager.get_context(chat_id, limit=6)
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—é
            history_text = ""
            for i, msg in enumerate(history[-6:], 1):
                role = "–ö–ª–∏–µ–Ω—Ç" if msg.get('is_user') else "–ë–æ—Ç"
                history_text += f"{i}. {role}: {msg.get('message', '')}\n"
            
            context_prompt = f"""–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –¥–∏–∞–ª–æ–≥–æ–≤ —Å–ª—É–∂–±—ã –≥—Ä—É–∑—á–∏–∫–æ–≤.

–ò–°–¢–û–†–ò–Ø –î–ò–ê–õ–û–ì–ê:
{history_text}

–ò–ó–í–õ–ï–ß–ï–ù–ù–´–ï –î–ê–ù–ù–´–ï:
–ì–æ—Ä–æ–¥: {extracted.get('city', '–Ω–µ —É–∫–∞–∑–∞–Ω')}
–ì—Ä—É–∑—á–∏–∫–æ–≤: {extracted.get('people', 0)}
–ß–∞—Å–æ–≤: {extracted.get('hours', 0)}
–¢–µ–ª–µ—Ñ–æ–Ω: {'–µ—Å—Ç—å' if extracted.get('phone') else '–Ω–µ—Ç'}
–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(extracted.get('keywords', [])) or '–Ω–µ—Ç'}
–û–ø–∏—Å–∞–Ω–∏–µ: {extracted.get('work_description', '')}

–ó–ê–î–ê–ß–ò –ê–ù–ê–õ–ò–ó–ê:

1. –¢–ò–ü –ö–õ–ò–ï–ù–¢–ê (customer_type):
   - "legal" –µ—Å–ª–∏: —Å–º–µ–Ω–∞, –æ–≤–æ—â–µ–±–∞–∑–∞, —Å–∫–ª–∞–¥, –º–∞–≥–∞–∑–∏–Ω, –æ—Ñ–∏—Å, —Ä–µ–≥—É–ª—è—Ä–Ω–æ, >4 –≥—Ä—É–∑—á–∏–∫–æ–≤, >8 —á–∞—Å–æ–≤, —Å—á–µ—Ç, –¥–æ–≥–æ–≤–æ—Ä
   - "private" –µ—Å–ª–∏: –ø–µ—Ä–µ–µ–∑–¥, –∫–≤–∞—Ä—Ç–∏—Ä–∞, –¥–∞—á–∞, –¥–æ–º, –º–µ–±–µ–ª—å, –≤–µ—â–∏, —Ä–∞–∑–æ–≤–∞—è —Ä–∞–±–æ—Ç–∞
   - "unknown" –µ—Å–ª–∏ –Ω–µ—è—Å–Ω–æ

2. –°–õ–ï–î–£–Æ–©–ï–ï –î–ï–ô–°–¢–í–ò–ï (next_action):
   - "ask_phone" –µ—Å–ª–∏: –∫–ª–∏–µ–Ω—Ç –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª ("–¥–∞", "–≤–µ—Ä–Ω–æ", "—Å–æ–≥–ª–∞—Å–µ–Ω"), –ò–õ–ò –µ—Å—Ç—å –≤—Å–µ –¥–∞–Ω–Ω—ã–µ (–≥–æ—Ä–æ–¥+–ª—é–¥–∏+—á–∞—Å—ã), –ò–õ–ò –¥–∏–∞–ª–æ–≥ –∑–∞—Å—Ç—Ä—è–ª
   - "show_price" –µ—Å–ª–∏: –µ—Å—Ç—å –≥–æ—Ä–æ–¥+–ª—é–¥–∏+—á–∞—Å—ã, –∫–ª–∏–µ–Ω—Ç —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç —Ü–µ–Ω—É, —Ç–∏–ø=private
   - "ask_details" –µ—Å–ª–∏: –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –ª—é–¥–µ–π –∏–ª–∏ —á–∞—Å–æ–≤
   - "ask_city" –µ—Å–ª–∏: –Ω–µ—Ç –≥–æ—Ä–æ–¥–∞
   - "clarify_customer_type" –µ—Å–ª–∏: –Ω–µ—è—Å–Ω–æ —é—Ä–ª–∏—Ü–æ –∏–ª–∏ —á–∞—Å—Ç–Ω–∏–∫, –Ω–æ –µ—Å—Ç—å –≤—Å–µ –¥–∞–Ω–Ω—ã–µ

3. –ì–û–¢–û–í–ù–û–°–¢–¨ –ö –°–î–ï–õ–ö–ï (ready_for_deal):
   - true –µ—Å–ª–∏: –µ—Å—Ç—å –≥–æ—Ä–æ–¥ AND (–ª—é–¥–∏ OR —á–∞—Å—ã) AND —Ç–∏–ø –∫–ª–∏–µ–Ω—Ç–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é >0.6
   - false –µ—Å–ª–∏ —á–µ–≥–æ-—Ç–æ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç

4. –ê–ù–ê–õ–ò–ó –ó–ê–¶–ò–ö–õ–ò–í–ê–ù–ò–Ø:
   - –ï—Å–ª–∏ –±–æ—Ç >2 —Ä–∞–∑ —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –æ–¥–Ω–æ –∏ —Ç–æ –∂–µ ‚Üí next_action = "ask_phone" (–≤—ã—Ö–æ–¥ –∏–∑ —Ü–∏–∫–ª–∞)

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON (–±–µ–∑ markdown):
{{
  "customer_type": "legal|private|unknown",
  "customer_confidence": 0.8,
  "next_action": "ask_phone",
  "reasoning": "–û–≤–æ—â–µ–±–∞–∑–∞ + —Å–º–µ–Ω–∞ 12—á + 4 –≥—Ä—É–∑—á–∏–∫–∞ = —é—Ä–ª–∏—Ü–æ. –ö–ª–∏–µ–Ω—Ç –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª ‚Üí –ø—Ä–æ—Å–∏–º —Ç–µ–ª–µ—Ñ–æ–Ω",
  "ready_for_deal": true
}}"""

            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": context_prompt}],
                response_format={"type": "json_object"},
                temperature=0.3,
                max_tokens=300
            )
            
            result = json.loads(response.choices[0].message.content)
            logger.info(f"üß† AI Context Analysis: {result['customer_type']} ({result['customer_confidence']:.2f}) ‚Üí {result['next_action']}")
            logger.info(f"   Reasoning: {result['reasoning']}")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Context analysis failed: {e}")
            return {
                'customer_type': 'unknown',
                'customer_confidence': 0.5,
                'next_action': 'ask_details',
                'reasoning': f'Error: {e}',
                'ready_for_deal': False
            }
    
    def _log_interaction(
        self,
        chat_id: str,
        message: str,
        response: str,
        metadata: Dict[str, Any],
        extracted: Dict[str, Any] = None,
        response_time_ms: int = None,
        avito_message_model = None
    ):
        """
        –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –≤ chats_log –¥–ª—è KPI Dashboard
        
        Args:
            chat_id: ID —á–∞—Ç–∞
            message: –°–æ–æ–±—â–µ–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–∞
            response: –û—Ç–≤–µ—Ç –±–æ—Ç–∞
            metadata: –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            extracted: –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            response_time_ms: –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –º—Å
            avito_message_model: –ú–æ–¥–µ–ª—å –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è (optional)
        """
        try:
            if not chat_id:
                return
            
            # –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
            comment_parts = []
            if metadata.get('customer_type'):
                comment_parts.append(f"Type:{metadata['customer_type']}")
            if metadata.get('action'):
                comment_parts.append(f"Action:{metadata['action']}")
            if metadata.get('deal_created'):
                comment_parts.append("DealCreated")
            if metadata.get('ai_override'):
                comment_parts.append("AI_Override")
            
            comment = " | ".join(comment_parts) if comment_parts else "No metadata"
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ chats_log (–¥–ª—è KPI Dashboard)
            if avito_message_model:
                try:
                    chats_log.create_chat_log(
                        model=avito_message_model,
                        is_success=True,
                        answer=response,
                        comment=comment,
                        extracted_data=extracted,
                        function_calls=None,  # –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º function calls –≤ –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ
                        quality_score=metadata.get('customer_type_confidence'),
                        experiment_variant='simple_processor_ai_over_ai',
                        deal_created=metadata.get('deal_created', False),
                        deal_id=metadata.get('deal_id'),
                        response_time_ms=response_time_ms
                    )
                    logger.info(f"‚úÖ Logged to chats_log: {chat_id}")
                except Exception as log_error:
                    logger.error(f"‚ùå Failed to log to chats_log: {log_error}")
            
            logger.info(f"üìù Interaction logged: {chat_id} | {comment}")
            
        except Exception as e:
            logger.error(f"‚ùå Error logging interaction: {e}")
    
    def _generate_response(
        self,
        message: str,
        action: str,
        customer_type: str,
        extracted: Dict[str, Any],
        pricing: Dict = None,
        chat_id: str = None
    ) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∂–∏–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ OpenAI —Å –º–∏–∫—Ä–æ-–ø—Ä–æ–º–ø—Ç–æ–º
        
        Args:
            message: –°–æ–æ–±—â–µ–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–∞
            action: –î–µ–π—Å—Ç–≤–∏–µ (ask_city, show_price, etc)
            customer_type: –¢–∏–ø –∫–ª–∏–µ–Ω—Ç–∞
            extracted: –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            pricing: –î–∞–Ω–Ω—ã–µ –æ —Ü–µ–Ω–∞—Ö
            chat_id: ID —á–∞—Ç–∞ (–¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
        
        Returns:
            –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
        """
        try:
            context_messages = []
            is_first_message = True
            bot_message_count = 0
            
            if chat_id:
                try:
                    history = chats_log.get_chat_history(chat_id, limit=5)
                    if history:
                        bot_message_count = len([m for m in history if m.get('role') == 'assistant'])
                        is_first_message = (bot_message_count == 0)
                        logger.debug(f"is_first_message={is_first_message}, bot_messages={bot_message_count}")
                        
                        # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 3 —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                        context_messages = history[-3:] if len(history) >= 3 else history
                except Exception as history_err:
                    logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏ –∏–∑ –ë–î –¥–ª—è is_first_message: {history_err}")
                    # Fallback –Ω–∞ in-memory context
                    history = self.context_manager.get_context(chat_id)
                    if history:
                        bot_message_count = len([m for m in history if not m.get('is_user')])
                        is_first_message = (bot_message_count == 0)
                        recent = history[-3:] if len(history) >= 3 else history
                        for msg in recent:
                            role = "user" if msg.get('is_user') else "assistant"
                            context_messages.append({
                                "role": role,
                                "content": msg.get('message', '')
                            })

            micro_prompt = build_micro_prompt(action, customer_type, extracted, pricing, is_first_message)
            
            messages = [
                {"role": "system", "content": micro_prompt}
            ]
            
            if context_messages:
                messages.extend(context_messages)
            
            messages.append({"role": "user", "content": message})
            
            logger.info(f"üé® Generating response for action='{action}'")
            
            response = self.openai_client.chat.completions.create(
                model=DEFAULT_MODEL,
                messages=messages,
                temperature=0.7,  # –ë–æ–ª—å—à–µ –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏
                max_tokens=300
            )
            
            generated = response.choices[0].message.content.strip()
            logger.info(f"‚úÖ Generated: {generated[:100]}...")
            
            return generated
            
        except Exception as e:
            logger.error(f"‚ùå Error generating response: {e}")
            # Fallback –∫ —à–∞–±–ª–æ–Ω—É
            return format_template(self._action_to_template(action), **extracted)
    
    def _action_to_template(self, action: str) -> str:
        """–ú–∞–ø–ø–∏–Ω–≥ action -> template_id –¥–ª—è fallback"""
        mapping = {
            'greeting': 'greeting',
            'ask_city': 'need_city',
            'ask_details': 'need_details',
            'ask_phone_legal': 'legal_no_price',
            'show_price_ask_phone': 'private_with_price',
            'reject_forbidden': 'forbidden_body_transport',
            'reject_min_workers': 'min_2_workers',
            'ask_phone_tackling': 'tackling_need_details',
            'city_not_available': 'city_not_in_list',
            'deal_created': 'deal_created',
        }
        return mapping.get(action, 'error_fallback')
    
    def _apply_business_logic(
        self,
        message: str,
        extracted: Dict[str, Any],
        chat_id: str = None,
        ad_data: dict = None
    ) -> Tuple[str, Dict]:
        """
        –ü—Ä–∏–º–µ–Ω–∏—Ç—å –±–∏–∑–Ω–µ—Å-–ø—Ä–∞–≤–∏–ª–∞ –∏ –≤—ã–±—Ä–∞—Ç—å template
        
        NO AI - —Ç–æ–ª—å–∫–æ –ª–æ–≥–∏–∫–∞!
        
        Returns:
            (response_text, metadata)
        """
        metadata = {
            'extracted': extracted,
            'customer_type': 'unknown',
            'action': 'unknown',
            'template_id': None,
            'deal_created': False
        }
        
        if extracted.get('is_forbidden_service', False):
        
            metadata['action'] = 'reject_forbidden'
            metadata['template_id'] = 'forbidden_body_transport'
            metadata['forbidden_reason'] = 'AI_detected'
            response = self._generate_response(message, 'reject_forbidden', 'unknown', extracted, chat_id=chat_id)
            return response, metadata
        
        is_forbidden, reason = self.business_rules.check_forbidden(extracted)
        if is_forbidden:
            metadata['action'] = 'reject_forbidden'
            metadata['template_id'] = 'forbidden_body_transport'
            metadata['forbidden_reason'] = f'keyword:{reason}'
            response = self._generate_response(message, 'reject_forbidden', 'unknown', extracted, chat_id=chat_id)
            return response, metadata
        
        is_floor_restricted, floor_reason = self.business_rules.check_floor_restriction(extracted)
        if is_floor_restricted:
            metadata['action'] = 'reject_floor_restriction'
            metadata['template_id'] = 'floor_restriction'
            extracted['floor'] = extracted.get('floor', 0)
            response = self._generate_response(message, 'reject_floor_restriction', 'unknown', extracted, chat_id=chat_id)
            return response, metadata
        
        is_heavy_item, heavy_reason = self.business_rules.check_heavy_item(extracted)
        if is_heavy_item:
            phone = extracted.get('phone', '')
            extracted['weight'] = extracted.get('single_item_weight', 0)
            if phone and phone != '':
                metadata['action'] = 'create_tackling_deal'
                metadata['deal_created'] = True
                metadata['template_id'] = 'heavy_item_tackling'
                response = self._generate_response(message, 'deal_created', 'unknown', extracted, chat_id=chat_id)
                return response, metadata
            else:
                metadata['action'] = 'ask_phone_tackling'
                metadata['template_id'] = 'heavy_item_tackling'
                response = self._generate_response(message, 'ask_phone_tackling', 'unknown', extracted, chat_id=chat_id)
                return response, metadata

        customer_type, confidence = self.business_rules.detect_customer_type(extracted)
        self._last_customer_type = customer_type
        metadata['customer_type'] = customer_type
        metadata['customer_type_confidence'] = confidence
        
        logger.info(f"üéØ Customer type: {customer_type} (confidence: {confidence:.2f})")
        
        # üß† AI CONTEXT ANALYZER: –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏—è –∏ —É—Ç–æ—á–Ω–µ–Ω–∏–µ —Ç–∏–ø–∞ –∫–ª–∏–µ–Ω—Ç–∞
        repeated_actions = self._count_repeated_actions(chat_id)
        is_stuck = any(count >= 2 for count in repeated_actions.values())
        
        if is_stuck or confidence < 0.7:
            if is_stuck:
                logger.warning(f"‚ö†Ô∏è Dialogue stuck: {repeated_actions}")
            
            ai_context = self._analyze_context_with_ai(extracted, chat_id)
            
            # Override customer_type –µ—Å–ª–∏ AI –±–æ–ª–µ–µ —É–≤–µ—Ä–µ–Ω
            if ai_context['customer_confidence'] > confidence:
                customer_type = ai_context['customer_type']
                confidence = ai_context['customer_confidence']
                metadata['customer_type'] = customer_type
                metadata['customer_type_confidence'] = confidence
                metadata['ai_override'] = True
                logger.info(f"ü§ñ AI override customer_type: {customer_type} ({confidence:.2f})")
            
            # –ï—Å–ª–∏ AI –≥–æ–≤–æ—Ä–∏—Ç ask_phone –∏ ready_for_deal ‚Üí –≤—ã—Ö–æ–¥–∏–º –∏–∑ –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏—è
            if ai_context['next_action'] == 'ask_phone' and ai_context['ready_for_deal']:
                phone = extracted.get('phone', '')
                if not phone:
                    logger.info(f"üöÄ AI suggests: ask_phone (breaking loop)")
                    
                    if customer_type == 'legal':
                        metadata['action'] = 'ask_phone_legal'
                        metadata['template_id'] = 'legal_no_price'
                        response = self._generate_response(message, 'ask_phone_legal', 'legal', extracted, chat_id=chat_id)
                        return response, metadata
                    else:
                        # –î–ª—è private: –ø–æ–ø—Ä–æ–±—É–µ–º –ø–æ–∫–∞–∑–∞—Ç—å —Ü–µ–Ω—É –µ—Å–ª–∏ –µ—Å—Ç—å –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
                        city = extracted.get('city', '')
                        people = extracted.get('people', 0)
                        hours = extracted.get('hours', 0)
                        
                        if city and people and hours:
                            pricing = self.pricing_calculator.get_city_pricing(city)
                            if pricing:
                                ppr = pricing['ppr']
                                min_hours = pricing['min_hours']
                                hours_charged = max(hours, min_hours)
                                total = people * hours_charged * ppr
                                
                                pricing_data = {
                                    'city': city,
                                    'ppr': ppr,
                                    'min_hours': min_hours,
                                    'people': people,
                                    'hours': hours,
                                    'hours_charged': hours_charged,
                                    'total': total
                                }
                                
                                metadata['action'] = 'show_price_ask_phone'
                                metadata['template_id'] = 'private_with_price'
                                metadata['pricing'] = pricing_data
                                response = self._generate_response(message, 'show_price_ask_phone', 'private', extracted, pricing_data, chat_id=chat_id)
                                return response, metadata
                        
                        # –ï—Å–ª–∏ –Ω–µ—Ç –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö - –ø—Ä–æ—Å—Ç–æ —Å–ø—Ä–æ—Å–∏–º —Ç–µ–ª–µ—Ñ–æ–Ω
                        metadata['action'] = 'ask_phone'
                        metadata['template_id'] = 'need_phone'
                        response = self._generate_response(message, 'ask_phone', customer_type, extracted, chat_id=chat_id)
                        return response, metadata
        
        # 3. Check tackling
        is_tackling = self.business_rules.check_tackling(extracted)
        if is_tackling:
            phone = extracted.get('phone', '')
            if phone and phone != '':
                # Create deal for tackling
                metadata['action'] = 'create_tackling_deal'
                metadata['deal_created'] = True
                metadata['template_id'] = 'tackling_deal_created'
                response = self._generate_response(message, 'deal_created', customer_type, extracted, chat_id=chat_id)
                return response, metadata
            else:
                metadata['action'] = 'ask_phone_tackling'
                metadata['template_id'] = 'tackling_need_phone'
                response = self._generate_response(message, 'ask_phone_tackling', customer_type, extracted, chat_id=chat_id)
                return response, metadata
        
        if customer_type == 'private':
            people = extracted.get('people', 0)
            if people > 0 and people < 2:
                metadata['action'] = 'reject_min_workers'
                metadata['template_id'] = 'min_2_workers'
                response = self._generate_response(message, 'reject_min_workers', customer_type, extracted, chat_id=chat_id)
                return response, metadata
        
        if customer_type == 'legal':
            return self._handle_legal_entity(message, extracted, metadata, chat_id)
        elif customer_type == 'private':
            return self._handle_private_customer(message, extracted, metadata, ad_data, chat_id)
        else:
            # Unknown - need more info
            return self._handle_unknown_customer(message, extracted, metadata, chat_id)
    
    def _handle_legal_entity(self, message: str, extracted: Dict, metadata: Dict, chat_id: str = None) -> Tuple[str, Dict]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —é—Ä–ª–∏—Ü–∞"""
        phone = extracted.get('phone', '')
        if phone and phone != '':
            deal_result = handle_create_bitrix_deal_legal(
                arguments={
                    'phone': phone,
                    'city': extracted.get('city', ''),
                    'hours': extracted.get('hours', 0),
                    'people': extracted.get('people', 0),
                    'work_type': extracted.get('work_description', ''),
                    'summary': extracted.get('work_description', ''),
                    'company_name': extracted.get('company_name', '')
                },
                context={'chat_id': chat_id}
            )
            
            if deal_result.get('success'):
                extracted['deal_id'] = deal_result.get('deal_id', '???')
                metadata['deal_id'] = deal_result.get('deal_id')
                metadata['action'] = 'create_legal_deal'
                metadata['deal_created'] = True
                metadata['template_id'] = 'legal_with_phone'
                logger.info(f"‚úÖ Legal deal created: #{deal_result.get('deal_id')}")
                response = self._generate_response(message, 'deal_created', 'legal', extracted, chat_id=chat_id)
                return response, metadata
            else:
                # –ë–∏—Ç—Ä–∏–∫—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - –Ω–µ –≤—Ä–µ–º –∫–ª–∏–µ–Ω—Ç—É
                logger.error(f"‚ùå Failed to create legal deal: {deal_result.get('error')}")
                metadata['action'] = 'bitrix_unavailable'
                metadata['deal_created'] = False
                metadata['template_id'] = 'bitrix_unavailable'
                metadata['error'] = deal_result.get('error', 'unknown')
                response = self._generate_response(message, 'bitrix_unavailable', 'legal', extracted, chat_id=chat_id)
                return response, metadata
        else:
            metadata['action'] = 'ask_phone_legal'
            metadata['template_id'] = 'legal_no_price'
            response = self._generate_response(message, 'ask_phone_legal', 'legal', extracted, chat_id=chat_id)
            return response, metadata
    
    def _handle_private_customer(
        self,
        message: str,
        extracted: Dict, 
        metadata: Dict,
        ad_data: dict = None,
        chat_id: str = None
    ) -> Tuple[str, Dict]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∏–∑–ª–∏—Ü–∞"""
        city = extracted.get('city', '')
        people = extracted.get('people', 0)
        hours = extracted.get('hours', 0)
        phone = extracted.get('phone', '')
        
        # Need city?
        if not city or city == '':
            metadata['action'] = 'ask_city'
            metadata['template_id'] = 'need_city'
            response = self._generate_response(message, 'ask_city', 'private', extracted, chat_id=chat_id)
            return response, metadata
        
        # Check if city in pricing
        pricing = self.pricing_calculator.get_city_pricing(city)
        if not pricing:
            metadata['action'] = 'city_not_available'
            metadata['template_id'] = 'city_not_in_list'
            extracted['city'] = city  # For prompt
            response = self._generate_response(message, 'city_not_available', 'private', extracted, chat_id=chat_id)
            return response, metadata
        
        # Need details?
        if not people or people == 0 or not hours or hours == 0:
            metadata['action'] = 'ask_details'
            metadata['template_id'] = 'need_details'
            response = self._generate_response(message, 'ask_details', 'private', extracted, chat_id=chat_id)
            return response, metadata
        
        # Calculate price
        ppr = pricing['ppr']
        min_hours = pricing['min_hours']
        hours_to_charge = max(hours, min_hours)
        total = people * hours_to_charge * ppr
        
        pricing_data = {
            'city': city,
            'ppr': ppr,
            'min_hours': min_hours,
            'people': people,
            'hours': hours,
            'hours_charged': hours_to_charge,
            'total': total
        }
        
        metadata['pricing'] = pricing_data
        
        if phone:
            deal_result = handle_create_bitrix_deal(
                arguments={
                    'phone': phone,
                    'city': city,
                    'hours': hours,
                    'people': people,
                    'price': total,
                    'summary': extracted.get('work_description', ''),
                    'floor': extracted.get('floor', 0),
                    'has_elevator': extracted.get('has_elevator', False)
                },
                context={'chat_id': chat_id}
            )
            
            if deal_result.get('success'):
                extracted['deal_id'] = deal_result.get('deal_id', '???')
                metadata['deal_id'] = deal_result.get('deal_id')
                metadata['action'] = 'create_private_deal'
                metadata['deal_created'] = True
                metadata['template_id'] = 'deal_created'
                logger.info(f"‚úÖ Private deal created: #{deal_result.get('deal_id')}")
                response = self._generate_response(message, 'deal_created', 'private', extracted, pricing_data, chat_id=chat_id)
                return response, metadata
            else:
                # –ë–∏—Ç—Ä–∏–∫—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - –Ω–µ –≤—Ä–µ–º –∫–ª–∏–µ–Ω—Ç—É
                logger.error(f"‚ùå Failed to create private deal: {deal_result.get('error')}")
                metadata['action'] = 'bitrix_unavailable'
                metadata['deal_created'] = False
                metadata['template_id'] = 'bitrix_unavailable'
                metadata['error'] = deal_result.get('error', 'unknown')
                response = self._generate_response(message, 'bitrix_unavailable', 'private', extracted, pricing_data, chat_id=chat_id)
                return response, metadata
        else:
            # Show price, ask phone
            metadata['action'] = 'show_price_ask_phone'
            metadata['template_id'] = 'private_with_price'
            response = self._generate_response(message, 'show_price_ask_phone', 'private', extracted, pricing_data, chat_id=chat_id)
            return response, metadata
    
    def _handle_unknown_customer(self, message: str, extracted: Dict, metadata: Dict, chat_id: str = None) -> Tuple[str, Dict]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–≥–¥–∞ —Ç–∏–ø –∫–ª–∏–µ–Ω—Ç–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω"""
        # Check if large order - need clarification
        if self.business_rules.should_clarify_large_order(extracted, 'unknown'):
            metadata['action'] = 'clarify_large_order'
            metadata['template_id'] = 'clarify_large_order'
            response = self._generate_response(message, 'clarify_large_order', 'unknown', extracted, chat_id=chat_id)
            return response, metadata
        
        # Need more info
        city = extracted.get('city', '')
        if not city or city == '':
            metadata['action'] = 'ask_city'
            metadata['template_id'] = 'need_city'
            response = self._generate_response(message, 'ask_city', 'unknown', extracted, chat_id=chat_id)
            return response, metadata
        
        metadata['action'] = 'ask_details'
        metadata['template_id'] = 'need_details'
        response = self._generate_response(message, 'ask_details', 'unknown', extracted, chat_id=chat_id)
        return response, metadata

